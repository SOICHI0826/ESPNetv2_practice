# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xex8lGn0QdwEtJRb52_qiRayjhX-I8Qs
"""

from google.colab import drive
drive.mount('/content/drive')

import os 
os.chdir('/content/drive/My Drive/ESPNetv2')

pwd

import argparse
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim
import torch.utils.data
import torch.utils.data.distributed
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import model as Net
import numpy as np
from utils import *
import random
import os
from lrschedule import LRScheduler

cudnn.benchmark = True

def compute_params(model):
  return sum([np.prod(p.size()) for p in model.parameters()])

def main(args):
  best_prec1 = 0.0

  if not os.path.isdir(args.savedir):
    os.mkdir(args.savedir)
  
  model = Net.EESPNet(classes = 1000, s = args.s)
  print('Network Parameters: ' + str(compute_params(model)))

  cuda_available = torch.cuda.is_available()

  num_gpus = torch.cuda.device_count()
  if num_gpus >= 1:
    model = torch.nn.DataParallel(model)
  if cuda_available:
    model = model.cuda()
  
  logFileLoc = args.savedir + 'logs.txt'
  if os.path.isfile(logFileLoc):
    logger = open(logFileLoc, 'a')
  else:
    logger = open(logFileLoc, 'w')
    logger.write("\n%s\t%s\t%s\t%s\t%s\t" % ('Epoch', 'Loss(Tr)', 'Loss(val)', 'top1(tr)', 'top1(val)'))
  
  optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum = args.momentum, weight_decay = args.weight_decay, nesterov = True)

  traindir = os.path.join(args.data, 'train')
  valdir = os.path.join(args.data, 'val')
  normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406],
                                   std = [0.229, 0.224, 0.225])
  train_loader = torch.utils.data.DataLoader(
      datasets.ImageFolder(
          traindir,
          transforms.Compose([
                              transforms.RandomResizedCrop(args.inpSize),
                              transforms.Resize(args.inpSize),
                              transforms.RandomHorizontalFlip(),
                              transforms.ToTensor(),
                              normalize,
          ])),
          batch_size = args.batch_size, shuffle = True,
          num_workers = args.workers, pin_memory = True
          )
  val_loader = torch.utils.data.DataLoader(
      datasets.ImageFolder(
          valdir, 
          transforms.Compose([
                              transforms.Resize(int(args.inpSize / 0.875)),
                              transforms.CenterCrop(args.inpSize),
                              transforms.ToTensor(),
                              normalize,
                              ])),
                              batch_size = args.batch_size, shuffle = False,
                              num_workers = args.workers, pin_memory = True
                              )
  step_sizes = [51, 101, 131, 161, 191, 221, 251, 281]

  customLR = LRScheduler(args.lr, 5, step_sizes)
  if args.start_epoch != 0:
    for epoch in range(args.start_epoch):
      customLR.get_lr(epoch)

  for epoch in range(args.start_epoch, args.epochs):
    lr_log = customLR.get_lr(epoch)
    for param_group in optimizer.param_groups:
      param_group['lr'] = lr_log
    print("LR for epoch {} = {:.5f}".format(epoch, lr_log))
    train_prec1, train_loss = train(train_loader, model, optimizer, epoch)
    val_prec1, val_loss = validate(val_loader, model)
    is_best = val_prec1.item() > best_prec1
    best_prec1 = max(val_prec1.item(), best_prec1)
    #back_check = True if epoch in step_store else False 

    logger.write("\n%d\t\t%.4f\t\t%.4f\t\t%.4f\t\t%.4f\t\t%.7f" %
                 (epoch, train_loss, val_loss, train_prec1, val_prec1, lr_log))
    logger.flush()

parser = argparse.ArgumentParser(description = 'ESPNetv2 Training on the ImageNet')
#parser.add_argument('--data', default = '/home/ubuntu/ILSVRC2015/Data/CLS-LOC/')
parser.add_argument('--data', default = '/content/drive/My Drive/ESPNetv2/data/')
#parser.add_argument('--data', metavar = 'DIR')
parser.add_argument('--workers', default = 12, type = int)
parser.add_argument('--epochs', default = 300, type = int)
parser.add_argument('--start_epoch', default = 0, type = int)
parser.add_argument('--batch_size', default = 128, type = int)
parser.add_argument('--lr', default = 0.1, type = float)
parser.add_argument('--momentum', default = 0.9, type = float)
parser.add_argument('--weight-decay', default = 4e-5, type = float)
#parser.add_argument('--resume', default ='', type = str)
parser.add_argument('--savedir', type = str, default = './results')
parser.add_argument('--s', default = 1, type = float)

parser.add_argument('--inpSize', default = 224, type = int)

args = parser.parse_args(args = [])
args.parallel = True
random.seed(1882)    
#random.manual_seed(1882)

args.savedir = args.savedir + '_s_' + str(args.s) + '_inp_' + str(args.inpSize) + os.sep

main(args)